<!DOCTYPE html>
<html lang='en'></html>
<head>
  <meta charset='utf-8' />
  <meta content='IE=edge,chrome=1' http-equiv='X-UA-Compatible' />
  <title>Classification datasets results</title>
  <meta content='' name='description' />
  <meta content='Rodrigo Benenson' name='author' />
  <meta content='width=device-width, initial-scale=1.0' name='viewport' />
  <link href="/are_we_there_yet/build/stylesheets/screen.css?1363119633" media="screen" rel="stylesheet" type="text/css" />
</head>
<body data-spy='scroll' data-target='#the-top-navbar'>
  <div class='container main-container'>
    <div class='masthead'>
      <div id='the-top-navbar'>
        <div>
          <ul class='nav nav-pills pull-right'>
            <li>
              <a href="/are_we_there_yet/build/#about">About</a>
            </li>
            <li>
              <a href="/are_we_there_yet/build/#datasets">Datasets</a>
            </li>
            <li>
              <a href="http://rodrigob.github.com/#contact">Contact</a>
            </li>
          </ul>
          <h3 class='muted'>Classification datasets results</h3>
        </div>
      </div>
    </div>
    <hr />
    <div class='jumbotron'>
  <h1>What is the class of this image ?</h1>
  <p class='lead'>
    Discover the current state of the art in objects classification.
  </p>
</div>
<div class='row datasets-list'>
  <ul class='span4 offset2 nav nav-stacked nav-pills'>
    <li><a href="#4d4e495354">MNIST</a></li>
    <li><a href="#43494641522d3130">CIFAR-10</a></li>
    <li><a href="#43494641522d313030">CIFAR-100</a></li>
    <li><a href="#53544c2d3130">STL-10</a></li>
    <li><a href="#5356484e">SVHN</a></li>
    <li><a href="#494c5356524332303132207461736b2031">ILSVRC2012 task 1</a></li>
  </ul>
</div>
<section>
  <div class='dataset-results container span9' id='4d4e495354' name='4d4e495354'>
    <h1 class='page-header'>MNIST<br/><small>who is the best in MNIST ?</small></h1>
    <div class='row dataset-preview'>
  <div class='span2'>
    <ul class='thumbnails'>
      <li>
        <a class="thumbnail" href="/are_we_there_yet/build/classification_datasets_results.html#4d4e495354"><img width="150px" height="150px" src="/are_we_there_yet/build/images/mnist.png?1363085077" />
        </a>
      </li>
    </ul>
  </div>
  <div class='span7'>
    <h3>
      <a href="/are_we_there_yet/build/classification_datasets_results.html#4d4e495354">MNIST</a>
      <small>21 results collected</small>
    </h3>
    <p>
      Units:
      error %
    </p>
    <blockquote><p><a href='http://yann.lecun.com/exdb/mnist/'>Classify handwriten digits</a>. Some additional results are available on the <a href='http://yann.lecun.com/exdb/mnist/'>original dataset page</a>.</p></blockquote>
  </div>
</div>
<!-- end of row -->
    <table class='table table-striped'>
      <thead>
        <tr>
          <th class='span2 pull-right'>
            Result
          </th>
          <th>Method</th>
          <th class='span2'>Venue</th>
          <th>Details</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class='span2'>0.21%</td>
          <td><a class="pdf_link" href="http://cs.nyu.edu/~wanli/dropc/">Regularization of Neural Networks using DropConnect</a></td>
          <td class='span2'>ICML 2013</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.23%</td>
          <td><a class="pdf_link" href="http://www.idsia.ch/~ciresan/data/cvpr2012.pdf">Multi-column Deep Neural Networks for Image Classiﬁcation </a></td>
          <td class='span2'>CVPR 2012</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.35%</td>
          <td><a class="pdf_link" href="http://arxiv.org/pdf/1003.0358.pdf">Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition</a></td>
          <td class='span2'>Neural Computation 2010</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-2' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-2' style='display:none'>
              <p>6-layer NN 784-2500-2000-1500-1000-500-10 (on GPU), uses elastic distortions</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.39%</td>
          <td><a class="pdf_link" href="http://books.nips.cc/papers/files/nips19/NIPS2006_0804.pdf">Efﬁcient Learning of Sparse Representations with an Energy-Based Model</a></td>
          <td class='span2'>NIPS 2006</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-3' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-3' style='display:none'>
              <p>Large conv. net, unsup pretraining, uses elastic distortions</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.4%</td>
          <td><a class="pdf_link" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=D1C7D701BD39935473808DA5A93426C5?doi=10.1.1.160.8494&rep=rep1&type=pdf">Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis</a></td>
          <td class='span2'>Document Analysis and Recognition 2003</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.45%</td>
          <td><a class="pdf_link" href="http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf">Maxout Networks</a></td>
          <td class='span2'>ICML 2013</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-5' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-5' style='display:none'>
              <p>Uses convolution. Does not use dataset augmentation.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.53%</td>
          <td><a class="pdf_link" href="http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf">What is the Best Multi-Stage Architecture for Object Recognition?</a></td>
          <td class='span2'>ICCV 2009</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-6' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-6' style='display:none'>
              <p>Large conv. net, unsup pretraining, no distortions</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.54%</td>
          <td><a class="pdf_link" href="http://www.keysers.net/daniel/files/Keysers--Deformation-Models--TPAMI2007.pdf">Deformation Models for Image Recognition</a></td>
          <td class='span2'>PAMI 2007</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-7' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-7' style='display:none'>
              <p>K-NN with non-linear deformation (IDM) (Preprocessing: shiftable edges)</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.54%</td>
          <td><a class="pdf_link" href="http://hal.inria.fr/docs/00/05/75/61/PDF/LauerSuenBlochPR.pdf">A trainable feature extractor for handwritten digit recognition</a></td>
          <td class='span2'>
               Journal
              Pattern Recognition 2007
            </td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-8' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-8' style='display:none'>
              <p>Trainable feature extractor + SVMs, uses affine distortions</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.56%</td>
          <td><a class="pdf_link" href="http://citeseerx.ist.psu.edu/icons/pdf.gif">Training Invariant Support Vector Machines</a></td>
          <td class='span2'>Machine Learning 2002</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-9' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-9' style='display:none'>
              <p>Virtual SVM, deg-9 poly, 2-pixel jittered (Preprocessing: deskewing)</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.59%</td>
          <td><a class="pdf_link" href="http://www.inb.uni-luebeck.de/publikationen/pdfs/LaBaMa08c.pdf">Simple Methods for High-Performance Digit Recognition Based on Sparse Coding</a></td>
          <td class='span2'>TNN 2008</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-10' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-10' style='display:none'>
              <p>Unsupervised sparse features + SVM, no distortions</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.62%</td>
          <td><a class="pdf_link" href="http://yann.lecun.com/exdb/publis/pdf/ranzato-cvpr-07.pdf">Unsupervised learning of invariant feature hierarchies with applications to object recognition</a></td>
          <td class='span2'>CVPR 2007</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-11' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-11' style='display:none'>
              <p>Large conv. net, unsup features, no distortions</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.63%</td>
          <td><a class="pdf_link" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=B2AAC2BC3824F19757CAC66986D5F3FF?doi=10.1.1.18.8852&rep=rep1&type=pdf">Shape matching and object recognition using shape contexts</a></td>
          <td class='span2'>PAMI 2002</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-12' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-12' style='display:none'>
              <p>K-NN, shape context matching (preprocessing: shape context feature extraction)</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.64%</td>
          <td><a class="pdf_link" href="http://www.icsi.berkeley.edu/pubs/vision/beyondspatial12.pdf">Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features</a></td>
          <td class='span2'>CVPR 2012</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.82%</td>
          <td>Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations</td>
          <td class='span2'>ICML 2009</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.94%</td>
          <td>Large-Margin kNN Classification using a Deep Encoder Network</td>
          <td class='span2'> 2009</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>0.95%</td>
          <td><a class="pdf_link" href="http://www.utstat.toronto.edu/~rsalakhu/papers/dbm.pdf">Deep Boltzmann Machines</a></td>
          <td class='span2'>AISTATS 2009</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>1.12%</td>
          <td>CS81: Learning words with Deep Belief Networks</td>
          <td class='span2'> 2008</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>1.19%</td>
          <td>Convolutional Neural Networks</td>
          <td class='span2'> 2003</td>
          <td>
            <a class='btn' data-content_id='#4d4e495354-method-18' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='4d4e495354-method-18' style='display:none'>
              <p>The ConvNN is based on the paper &#8220;Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis&#8221;.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>1.2%</td>
          <td>Reducing the dimensionality of data with neural networks</td>
          <td class='span2'> 2006</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>1.5%</td>
          <td>Deep learning via semi-supervised embedding</td>
          <td class='span2'> 2008</td>
          <td>
          </td>
        </tr>
      </tbody>
    </table>
    <small>Something is off, something is missing ? Feel free to <a href='/are_we_there_yet/build/new_result_form.html'>fill in the form</a>.</small>
  </div>
</section>
<!-- end of dataset section -->
<hr />
<section>
  <div class='dataset-results container span9' id='43494641522d3130' name='43494641522d3130'>
    <h1 class='page-header'>CIFAR-10<br/><small>who is the best in CIFAR-10 ?</small></h1>
    <div class='row dataset-preview'>
  <div class='span2'>
    <ul class='thumbnails'>
      <li>
        <a class="thumbnail" href="/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130"><img width="150px" height="150px" src="/are_we_there_yet/build/images/cifar_10.png?1363085077" />
        </a>
      </li>
    </ul>
  </div>
  <div class='span7'>
    <h3>
      <a href="/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130">CIFAR-10</a>
      <small>9 results collected</small>
    </h3>
    <p>
      Units:
      precision %
    </p>
    <blockquote><p>Classify <a href='http://www.cs.toronto.edu/~kriz/cifar.html'>32x32 colour images</a>.</p></blockquote>
  </div>
</div>
<!-- end of row -->
    <table class='table table-striped'>
      <thead>
        <tr>
          <th class='span2 pull-right'>
            Result
          </th>
          <th>Method</th>
          <th class='span2'>Venue</th>
          <th>Details</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class='span2'>90.68%</td>
          <td><a class="pdf_link" href="http://cs.nyu.edu/~wanli/dropc/">Regularization of Neural Networks using DropConnect</a></td>
          <td class='span2'>ICML 2013</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>90.65%</td>
          <td><a class="pdf_link" href="http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf">Maxout Networks</a></td>
          <td class='span2'>ICML 2013</td>
          <td>
            <a class='btn' data-content_id='#43494641522d3130-method-1' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='43494641522d3130-method-1' style='display:none'>
              <p>This result was obtained using both convolution and synthetic translations / horizontal reflections of the training data.</p>
              
              <p>Reaches 88.32% when using convolution, but without any synthetic transformations of the training data.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>90.5%</td>
          <td><a class="pdf_link" href="http://www.cs.toronto.edu/~jasper/bayesopt.pdf">Practical Bayesian Optimization of Machine Learning Algorithms </a></td>
          <td class='span2'>NIPS 2012</td>
          <td>
            <a class='btn' data-content_id='#43494641522d3130-method-2' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='43494641522d3130-method-2' style='display:none'>
              <p>Reaches 85.02% without data augmentation.</p>
              
              <p>With data augmented with horizontal reﬂections and translations, 90.5% accuracy on test set is achieved.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>89%</td>
          <td><a class="pdf_link" href="http://books.nips.cc/papers/files/nips25/NIPS2012_0534.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a></td>
          <td class='span2'>NIPS 2012</td>
          <td>
            <a class='btn' data-content_id='#43494641522d3130-method-3' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='43494641522d3130-method-3' style='display:none'>
              <p>87% error on the unaugmented data.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>88.79%</td>
          <td><a class="pdf_link" href="http://www.idsia.ch/~ciresan/data/cvpr2012.pdf">Multi-Column Deep Neural Networks for Image Classification </a></td>
          <td class='span2'>CVPR 2012</td>
          <td>
            <a class='btn' data-content_id='#43494641522d3130-method-4' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='43494641522d3130-method-4' style='display:none'>
              <p><a href='http://www.idsia.ch/~ciresan/data/cvpr2012-supp.pdf'>Supplemental material</a>, <a href='http://arxiv.org/pdf/1202.2745v1.pdf'>Technical Report</a></p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>84.87%</td>
          <td><a class="pdf_link" href="http://arxiv.org/pdf/1301.3557.pdf">Stochastic Pooling for Regularization of Deep Convolutional Neural Networks</a></td>
          <td class='span2'>arXiv 2013</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>84.4%</td>
          <td><a class="pdf_link" href="http://arxiv.org/pdf/1207.0580.pdf">Improving neural networks by preventing co-adaptation of feature detectors</a></td>
          <td class='span2'>arXiv 2012</td>
          <td>
            <a class='btn' data-content_id='#43494641522d3130-method-6' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='43494641522d3130-method-6' style='display:none'>
              <p>So called &#8220;dropout&#8221; method.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>83.96%</td>
          <td><a class="pdf_link" href="http://books.nips.cc/papers/files/nips25/NIPS2012_1484.pdf">Discriminative Learning of Sum-Product Networks</a></td>
          <td class='span2'>NIPS 2012</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>79.6 %</td>
          <td><a class="pdf_link" href="http://www.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf">An Analysis of Single-Layer Networks in Unsupervised Feature Learning </a></td>
          <td class='span2'>AISTATS 2011</td>
          <td>
            <a class='btn' data-content_id='#43494641522d3130-method-8' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='43494641522d3130-method-8' style='display:none'>
              <ol>
                <li>6% obtained using K-means over whitened patches, with triangle encoding and 4000 features (clusters).</li>
                </ol>
            </div>
          </td>
        </tr>
      </tbody>
    </table>
    <small>Something is off, something is missing ? Feel free to <a href='/are_we_there_yet/build/new_result_form.html'>fill in the form</a>.</small>
  </div>
</section>
<!-- end of dataset section -->
<hr />
<section>
  <div class='dataset-results container span9' id='43494641522d313030' name='43494641522d313030'>
    <h1 class='page-header'>CIFAR-100<br/><small>who is the best in CIFAR-100 ?</small></h1>
    <div class='row dataset-preview'>
  <div class='span2'>
    <ul class='thumbnails'>
      <li>
        <a class="thumbnail" href="/are_we_there_yet/build/classification_datasets_results.html#43494641522d313030"><img width="150px" height="150px" src="/are_we_there_yet/build/images/cifar_100.png?1363085077" />
        </a>
      </li>
    </ul>
  </div>
  <div class='span7'>
    <h3>
      <a href="/are_we_there_yet/build/classification_datasets_results.html#43494641522d313030">CIFAR-100</a>
      <small>3 results collected</small>
    </h3>
    <p>
      Units:
      precision %
    </p>
    <blockquote><p>Classify <a href='http://www.cs.toronto.edu/~kriz/cifar.html'>32x32 colour images</a>.</p></blockquote>
  </div>
</div>
<!-- end of row -->
    <table class='table table-striped'>
      <thead>
        <tr>
          <th class='span2 pull-right'>
            Result
          </th>
          <th>Method</th>
          <th class='span2'>Venue</th>
          <th>Details</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class='span2'>61.43%</td>
          <td><a class="pdf_link" href="http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf">Maxout Networks</a></td>
          <td class='span2'>ICML 2013</td>
          <td>
            <a class='btn' data-content_id='#43494641522d313030-method-0' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='43494641522d313030-method-0' style='display:none'>
              <p>Uses convolution. Does not use dataset agumentation.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>57.49%</td>
          <td><a class="pdf_link" href="http://arxiv.org/pdf/1301.3557.pdf">Stochastic Pooling for Regularization of Deep Convolutional Neural Networks</a></td>
          <td class='span2'>arXiv 2013</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>54.23%</td>
          <td><a class="pdf_link" href="http://www.eecs.berkeley.edu/~jiayq/assets/pdf/cvpr12_pooling.pdf">Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features</a></td>
          <td class='span2'>CVPR 2012</td>
          <td>
          </td>
        </tr>
      </tbody>
    </table>
    <small>Something is off, something is missing ? Feel free to <a href='/are_we_there_yet/build/new_result_form.html'>fill in the form</a>.</small>
  </div>
</section>
<!-- end of dataset section -->
<hr />
<section>
  <div class='dataset-results container span9' id='53544c2d3130' name='53544c2d3130'>
    <h1 class='page-header'>STL-10<br/><small>who is the best in STL-10 ?</small></h1>
    <div class='row dataset-preview'>
  <div class='span2'>
    <ul class='thumbnails'>
      <li>
        <a class="thumbnail" href="/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130"><img width="150px" height="150px" src="/are_we_there_yet/build/images/stl_10.png?1363085077" />
        </a>
      </li>
    </ul>
  </div>
  <div class='span7'>
    <h3>
      <a href="/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130">STL-10</a>
      <small>6 results collected</small>
    </h3>
    <p>
      Units:
      precision %
    </p>
    <blockquote><p>Similar to CIFAR-10 but with 96x96 images. <a href='http://www.stanford.edu/~acoates/stl10/'>Original dataset website</a>.</p></blockquote>
  </div>
</div>
<!-- end of row -->
    <table class='table table-striped'>
      <thead>
        <tr>
          <th class='span2 pull-right'>
            Result
          </th>
          <th>Method</th>
          <th class='span2'>Venue</th>
          <th>Details</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class='span2'>62.3% (± 1%)</td>
          <td><a class="pdf_link" href="http://homes.cs.washington.edu/~rcg/papers/dspn.pdf">Discriminative Learning of Sum-Product Networks</a></td>
          <td class='span2'>NIPS 2012</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>61%</td>
          <td><a class="pdf_link" href="http://books.nips.cc/papers/files/nips25/NIPS2012_1467.pdf">Deep Learning of Invariant Features via Simulated Fixations in Video</a></td>
          <td class='span2'>NIPS 2012 2012</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>60.1% (± 1%)</td>
          <td><a class="pdf_link" href="http://www.stanford.edu/~acoates/papers/coatesng_nips_2011.pdf">Selecting Receptive Fields in Deep Networks </a></td>
          <td class='span2'>NIPS 2011</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>58.7%</td>
          <td><a class="pdf_link" href="http://web.eecs.umich.edu/~honglak/icml12-invariantFeatureLearning.pdf">Learning Invariant Representations with Local Transformations</a></td>
          <td class='span2'>ICML 2012</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>58.28%</td>
          <td><a class="pdf_link" href="http://arxiv.org/pdf/1302.5056v1.pdf">Pooling-Invariant Image Feature Learning </a></td>
          <td class='span2'>arXiv 2012</td>
          <td>
            <a class='btn' data-content_id='#53544c2d3130-method-4' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='53544c2d3130-method-4' style='display:none'>
              <p>1600 codes, learnt using 2x PDL</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>56.5%</td>
          <td><a class="pdf_link" href="http://ai.stanford.edu/~wzou/nips_ZouZhuNgYu12.pdf">Deep Learning of Invariant Features via Simulated Fixations in Video</a></td>
          <td class='span2'>NIPS 2012</td>
          <td>
            <a class='btn' data-content_id='#53544c2d3130-method-5' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='53544c2d3130-method-5' style='display:none'>
              <p>Trained also with video (unrelated to STL-10) obtained 61%</p>
            </div>
          </td>
        </tr>
      </tbody>
    </table>
    <small>Something is off, something is missing ? Feel free to <a href='/are_we_there_yet/build/new_result_form.html'>fill in the form</a>.</small>
  </div>
</section>
<!-- end of dataset section -->
<hr />
<section>
  <div class='dataset-results container span9' id='5356484e' name='5356484e'>
    <h1 class='page-header'>SVHN<br/><small>who is the best in SVHN ?</small></h1>
    <div class='row dataset-preview'>
  <div class='span2'>
    <ul class='thumbnails'>
      <li>
        <a class="thumbnail" href="/are_we_there_yet/build/classification_datasets_results.html#5356484e"><img width="150px" height="150px" src="http://ufldl.stanford.edu/housenumbers/32x32eg.png" />
        </a>
      </li>
    </ul>
  </div>
  <div class='span7'>
    <h3>
      <a href="/are_we_there_yet/build/classification_datasets_results.html#5356484e">SVHN</a>
      <small>5 results collected</small>
    </h3>
    <p>
      Units:
      error %
    </p>
    <blockquote><p><a href='http://ufldl.stanford.edu/housenumbers'>The Street View House Numbers (SVHN) Dataset</a>.</p>

<p>SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.</p></blockquote>
  </div>
</div>
<!-- end of row -->
    <table class='table table-striped'>
      <thead>
        <tr>
          <th class='span2 pull-right'>
            Result
          </th>
          <th>Method</th>
          <th class='span2'>Venue</th>
          <th>Details</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class='span2'>1.94%</td>
          <td><a class="pdf_link" href="http://cs.nyu.edu/~wanli/dropc/">Regularization of Neural Networks using DropConnect</a></td>
          <td class='span2'>ICML 2013</td>
          <td>
          </td>
        </tr>
        <tr>
          <td class='span2'>2%</td>
          <td><a class="pdf_link" href="http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf">Estimated human performance</a></td>
          <td class='span2'>NIPS 2011</td>
          <td>
            <a class='btn' data-content_id='#5356484e-method-1' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='5356484e-method-1' style='display:none'>
              <p>Based on the paper that introduced the dataset <a href='http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf'>Reading Digits in Natural Images with Unsupervised Feature Learning</a>, section 5.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>2.47%</td>
          <td><a class="pdf_link" href="http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf">Maxout Networks</a></td>
          <td class='span2'>ICML 2013</td>
          <td>
            <a class='btn' data-content_id='#5356484e-method-2' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='5356484e-method-2' style='display:none'>
              <p>This result was obtained using convolution but not any synthetic transformations of the training data.</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>2.8%</td>
          <td><a class="pdf_link" href="http://arxiv.org/pdf/1301.3557.pdf">Stochastic Pooling for Regularization of Deep Convolutional Neural Networks</a></td>
          <td class='span2'>arXiv 2013</td>
          <td>
            <a class='btn' data-content_id='#5356484e-method-3' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='5356484e-method-3' style='display:none'>
              <p>64-64-128 Stochastic Pooling</p>
            </div>
          </td>
        </tr>
        <tr>
          <td class='span2'>4.9%</td>
          <td><a class="pdf_link" href="http://yann.lecun.com/exdb/publis/pdf/sermanet-icpr-12.pdf">Convolutional neural networks applied to house numbers digit classiﬁcation</a></td>
          <td class='span2'>ICPR 2012</td>
          <td>
            <a class='btn' data-content_id='#5356484e-method-4' data-html='true' data-original-title='Additional information' data-placement='left' data-toggle='popover' data-trigger='hover' rel='popover'>
              Details
            </a>
            <div id='5356484e-method-4' style='display:none'>
              <p>ConvNet / MS / L4 / Padded</p>
            </div>
          </td>
        </tr>
      </tbody>
    </table>
    <small>Something is off, something is missing ? Feel free to <a href='/are_we_there_yet/build/new_result_form.html'>fill in the form</a>.</small>
  </div>
</section>
<!-- end of dataset section -->
<hr />
<section>
  <div class='dataset-results container span9' id='494c5356524332303132207461736b2031' name='494c5356524332303132207461736b2031'>
    <h1 class='page-header'>ILSVRC2012 task 1<br/><small>who is the best in ILSVRC2012 task 1 ?</small></h1>
    <div class='row dataset-preview'>
  <div class='span2'>
    <ul class='thumbnails'>
      <li>
        <a class="thumbnail" href="http://www.image-net.org/challenges/LSVRC/2012/results.html#t1"><img width="150px" height="150px" src="/are_we_there_yet/build/images/ilsvrc2012_task1.png?1363085077" />
        </a>
      </li>
    </ul>
  </div>
  <div class='span7'>
    <h3>
      <a class="external_link" href="http://www.image-net.org/challenges/LSVRC/2012/results.html#t1">ILSVRC2012 task 1</a>
    </h3>
    <p>
      Units:
      Error (5 guesses)
    </p>
    <blockquote>
      <p>1000 categories <a href='http://www.image-net.org/challenges/LSVRC/2012/index'>classification challenge</a>. With tens of thousands of training, validation and testing images.</p>
      
      <p>See this interesting <a href='http://www.image-net.org/challenges/LSVRC/2012/analysis/'>comparative analysis</a>.</p>
    </blockquote>
  </div>
</div>
<!-- end of row -->
    <p>Results are collected in the following <a class='external_link' href='http://www.image-net.org/challenges/LSVRC/2012/results.html#t1'>external webpage</a></p>
  </div>
</section>
<!-- end of dataset section -->
<hr />
    <div class='row'>
      <footer class='span12'>
        <p>Last updated on 2013-09-11.</p>
        
        <p>&#169; 2013 Rodrigo Benenson.</p>
        
        <p>Built using <a href='http://middlemanapp.com'>middleman</a> and <a href='http://twitter.github.com/bootstrap'>bootstrap</a>.</p>
      </footer>
    </div>
  </div>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js" type="text/javascript"></script>
  <script src="/are_we_there_yet/build/javascripts/main.js?1363085077" type="text/javascript"></script>
  <script src="/are_we_there_yet/build/javascripts/plugins.js?1363085077" type="text/javascript"></script>
  <script src="/are_we_there_yet/build/javascripts/script.js" type="text/javascript"></script>
  <!-- Google Analytics -->
  <script type='text/javascript'>
    //<![CDATA[
       var _gaq=[['_setAccount','UA-80935-10'],['_trackPageview']];
       (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
       g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
       s.parentNode.insertBefore(g,s)}(document,'script'));
    //]]>
  </script>
</body>
